{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ecb603a-6a07-4f29-84b5-2a94a7655b44",
   "metadata": {},
   "source": [
    "Zachary Proom\n",
    "\n",
    "EN.605.646.81: Natural Language Processing\n",
    "\n",
    "# Lab #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a8712-085d-4e85-8d9b-3b2ae4f00bb5",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86271b6b-7e04-4b4d-b9d6-ad4f20b2995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from charlm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43087e8-25f1-47ed-b885-3948bb01ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylm = train_char_lm('subtitles.txt', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4403957-8f55-470b-9052-9428bad74624",
   "metadata": {},
   "source": [
    "Below are the continuations for 'atio':"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae8d4f9-9390-42c8-91a3-976840abbf71",
   "metadata": {},
   "source": [
    "print_probs(mylm, 'atio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18f4a3-e7e5-45b3-9e2a-6ae3fa1daa6f",
   "metadata": {},
   "source": [
    "Next, here are the continuations for 'nivi':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d7e52e-9f79-4af2-aa4a-59e5ab84d8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n', 0.8), ('e', 0.1), ('s', 0.1)]\n"
     ]
    }
   ],
   "source": [
    "print_probs(mylm, 'nivi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5777eb-7874-452f-91cd-1f2dc1cf4ad4",
   "metadata": {},
   "source": [
    "Finally, here are the continuations for 'supe':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519f3941-b110-4a4a-b57f-c87483c77243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('r', 0.9992144540455616), ('s', 0.0007855459544383347)]\n"
     ]
    }
   ],
   "source": [
    "print_probs(mylm, 'supe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b170a4-4a87-4ad6-a1cf-00516921236b",
   "metadata": {},
   "source": [
    "Next, I generate some random strings (up to 80 characters) from the model, using generate_text():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887123cc-7133-41f0-bf70-4f93e30999d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"You're company infect descene.\\nWhat?\\nMormous.\\nPay mom.\\nSince a this, I won.\\nI'm \",\n",
       " \"Nothing you recept well you doing for Nicole.\\nNo, it's to cool.\\n- Shave the cant\",\n",
       " 'Are you.\\nOverpopulational Cell you have an in Russion even anyone go intribute d',\n",
       " 'About it.\\nCopy that was Dr. X.\\nLesbian.\\n- l make land. Fabrief.\\nl does no long w',\n",
       " 'Where we door.\\n-You... at 4:15 PM, MMMMM. HEAR TO THE BEGINNING WHAT HAVE A LOT ',\n",
       " \"Cheer to understantibility family.\\n'And girls.\\nLucius if you the proposed to an \",\n",
       " \"Get the worry.\\nGo back to do.\\nUnderstand-- - # Be can didn't talk togethere hund\",\n",
       " \"Do you can was we first statement.\\nAt lease!\\nOnly only man, I'm almost of oil.\\nA\",\n",
       " \"Get in the people my. Yeah, I'll fight, Agnew, you.\\nThe odd the drank.\\nEleveryth\",\n",
       " \"You the freedom. - Well, that.\\nIt's missie: Hero.\\nYou're have and take do. ~ Oh?\",\n",
       " \"You!\\nThey're resence in he true.\\nThat's times by. Thursday who did you teless yo\",\n",
       " 'Ah, my cause!\\nMay 1.0 LOL.\\nNow I know.\\nWHAT?\\nI know who do repeat!\\nHer Mothere.\\n',\n",
       " 'Joseph had a bit ghost breats. here?\\nWhat?\\nMomowaka too.\\nSorry to blade a stoppe',\n",
       " \"You this won't know.\\n- What?\\nYou see time soldiers all the looking in him.\\nOkay,\",\n",
       " \"Everybody sistandau defeature.\\nI've being, almost had backpackage.\\nThis the turn\",\n",
       " \"I willing with you've been work?\\nRight-blad... ok, I am...\\nThe greaten, broke Da\",\n",
       " 'One of you had to the been real is so heard to eart!\\nDo your rentired.\\nAh! No! G',\n",
       " '- We left to fight. Clyde and I wenty is in the fools!\\nDean totalking passportan',\n",
       " \"Stop!\\nIgor, broke a human invited syster Brand.\\nYou're going? Have to resume it \",\n",
       " 'Good anythink weÂ´re ship with you beautiful. - You ruin it?\\nJust give means in.\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1) # Set a random seed so the results are reproducible.\n",
    "\n",
    "num_sentences = 20\n",
    "sentence_list = [] # Store sentences in this list.\n",
    "for i in range(0, num_sentences): # Generate 10 random sentences.\n",
    "     sentence_list.append(generate_text(mylm, 4, 80))\n",
    "sentence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9f393-033f-47b0-ada9-c1067513913d",
   "metadata": {},
   "source": [
    "Below are three of my favorite sentences produced by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a98dbf-0377-4330-903d-36a219f32807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence:\n",
      "Where we door.\n",
      "-You... at 4:15 PM, MMMMM. HEAR TO THE BEGINNING WHAT HAVE A LOT \n",
      "\n",
      "Second sentence:\n",
      "Ah, my cause!\n",
      "May 1.0 LOL.\n",
      "Now I know.\n",
      "WHAT?\n",
      "I know who do repeat!\n",
      "Her Mothere.\n",
      "\n",
      "\n",
      "Third sentence:\n",
      "Stop!\n",
      "Igor, broke a human invited syster Brand.\n",
      "You're going? Have to resume it \n"
     ]
    }
   ],
   "source": [
    "print(\"First sentence:\")\n",
    "print(sentence_list[4])\n",
    "print(\"\")\n",
    "print(\"Second sentence:\")\n",
    "print(sentence_list[11])\n",
    "print(\"\")\n",
    "print(\"Third sentence:\")\n",
    "print(sentence_list[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81bb6ff-6a2c-49ca-a096-6e4638b6a43f",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d0b1f-dac3-4fbe-b13b-e53b191acc69",
   "metadata": {},
   "source": [
    "Below I demonstrate that my perplexity() function works on the test sentences provided in the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1a36fb-ffea-4021-90f6-aba3874a1b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9091903673746224"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity('The boy loves his mother', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0febc1c3-86f9-4d31-a07f-7a8b28da2fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.606972940490915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity('The student loves homework', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d434f5bd-b5ad-4dc6-9d6c-2eb39244da9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity('The yob loves homework', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc389e32-7cb4-455d-a77b-5192712817dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.711236000904451"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity('It is raining in London', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9172783d-5141-4672-b2a1-646469bd0619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity('asdfjkl; qwerty', mylm, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13c627-6190-4172-be6f-571cb5b05070",
   "metadata": {},
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74126264-e428-4b31-987c-7bf7e1b4d5ea",
   "metadata": {},
   "source": [
    "Below I demonstrate that my smoothed_perplexity() function works on the same test sentences above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1236b4-52b1-46d9-a2c5-be87b48f068a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9091903673746224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_perplexity('The boy loves his mother', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d15115-7059-40ed-b2de-02cc3107bf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.606972940490915"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_perplexity('The student loves homework', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875c711e-084e-4a2a-ae66-906235ad385d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8414414343307257"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_perplexity('The yob loves homework', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "446280b7-7211-444b-8f4e-d77597444cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.711236000904451"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_perplexity('It is raining in London', mylm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d60b565-e1c8-4bea-9fe3-a0c051c7d11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.01098439084096"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_perplexity('asdfjkl; qwerty', mylm, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2bbd9-5fca-48fc-bcbf-221fc29c6fdf",
   "metadata": {},
   "source": [
    "## d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd13b6a-0e2c-4a51-926c-dfa21280dd0a",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed217f-1d33-4a40-b168-bbfae482a61d",
   "metadata": {},
   "source": [
    "First, I train the six unigram models, one per language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5571b224-d8ea-4155-aee5-dbd2f2a692d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_unigram = train_char_lm('da.train.txt', 0)\n",
    "de_unigram = train_char_lm('de.train.txt', 0)\n",
    "en_unigram = train_char_lm('en.train.txt', 0)\n",
    "fr_unigram = train_char_lm('fr.train.txt', 0)\n",
    "it_unigram = train_char_lm('it.train.txt', 0)\n",
    "nl_unigram = train_char_lm('nl.train.txt', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b3c5d-7dc6-4c89-b29a-55dbb4ee3ee7",
   "metadata": {},
   "source": [
    "Below I loop through each line of the test file. For each line, I calculate the smoothed perplexity for each of the six unigram models and return the language code for the model with the lowest smoothed perplexity. For the first line in the test file, I show all the smoothed perplexity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17c4be85-727b-42dd-80df-7d91260a495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed perplexity scores for the six unigram models:\n",
      "da_unigram: 29.315540257386687\n",
      "de_unigram: 29.519916658268038\n",
      "en_unigram: 20.720193646415265\n",
      "fr_unigram: 21.573215271232797\n",
      "it_unigram: 23.4811101760081\n",
      "nl_unigram: 26.631669733860637\n"
     ]
    }
   ],
   "source": [
    "predicted_languages = []\n",
    "actual_languages = []\n",
    "with open(\"test.txt\") as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        split_tab = line.split(\"\\t\")\n",
    "        actual_language = split_tab[0]\n",
    "        actual_languages.append(actual_language)\n",
    "        text = split_tab[1] # Only use the text after the tab. Ignore the correct language code.\n",
    "        da_score = smoothed_perplexity(text, da_unigram, 0)\n",
    "        de_score = smoothed_perplexity(text, de_unigram, 0)\n",
    "        en_score = smoothed_perplexity(text, en_unigram, 0)\n",
    "        fr_score = smoothed_perplexity(text, fr_unigram, 0)\n",
    "        it_score = smoothed_perplexity(text, it_unigram, 0)\n",
    "        nl_score = smoothed_perplexity(text, nl_unigram, 0)\n",
    "        min_score = min(da_score, de_score, en_score, fr_score, it_score, nl_score)\n",
    "        if min_score == da_score:\n",
    "            predicted_language = \"da\"\n",
    "        elif min_score == de_score:\n",
    "            predicted_language = \"de\"\n",
    "        elif min_score == en_score:\n",
    "            predicted_language = \"en\"\n",
    "        elif min_score == fr_score:\n",
    "            predicted_language = \"fr\"\n",
    "        elif min_score == it_score:\n",
    "            predicted_language = \"it\"\n",
    "        elif min_score == nl_score:\n",
    "            predicted_language = \"nl\"\n",
    "        predicted_languages.append(predicted_language)\n",
    "        # Print all the smoothed perplexity scores.\n",
    "        if i == 0:\n",
    "            print(\"Smoothed perplexity scores for the six unigram models:\")\n",
    "            print(\"da_unigram: \" + str(da_score))\n",
    "            print(\"de_unigram: \" + str(de_score))\n",
    "            print(\"en_unigram: \" + str(en_score))\n",
    "            print(\"fr_unigram: \" + str(fr_score))\n",
    "            print(\"it_unigram: \" + str(it_score))\n",
    "            print(\"nl_unigram: \" + str(nl_score))\n",
    "        i += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35da9bc-2bba-45b5-a792-c839fc71696e",
   "metadata": {},
   "source": [
    "I calculate and report accuracy for the six languages below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a369f453-f641-456e-a83f-6691e37a11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_language_counts = {\n",
    "    \"da\": 0,\n",
    "    \"de\": 0,\n",
    "    \"en\": 0,\n",
    "    \"fr\": 0,\n",
    "    \"it\": 0,\n",
    "    \"nl\": 0\n",
    "}\n",
    "correct_prediction_counts = {\n",
    "    \"da\": 0,\n",
    "    \"de\": 0,\n",
    "    \"en\": 0,\n",
    "    \"fr\": 0,\n",
    "    \"it\": 0,\n",
    "    \"nl\": 0\n",
    "}\n",
    "for i in range(0, len(actual_languages)):\n",
    "    actual_language_counts[actual_languages[i]] += 1\n",
    "    if predicted_languages[i] == actual_languages[i]:\n",
    "        correct_prediction_counts[predicted_languages[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76d14b52-6d4f-4024-9bf5-7fce84b21e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'da': 37, 'de': 103, 'en': 183, 'fr': 41, 'it': 160, 'nl': 172}\n",
      "{'da': 200, 'de': 200, 'en': 200, 'fr': 200, 'it': 200, 'nl': 200}\n",
      "18.5\n",
      "51.5\n",
      "91.5\n",
      "20.5\n",
      "80.0\n",
      "86.0\n"
     ]
    }
   ],
   "source": [
    "print(correct_prediction_counts)\n",
    "print(actual_language_counts)\n",
    "print(correct_prediction_counts[\"da\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"de\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"en\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"fr\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"it\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"nl\"]/actual_language_counts[\"da\"]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e27991-b62e-4d13-9502-6815480d925d",
   "metadata": {},
   "source": [
    "The unigram models produce the following results, which are displayed above:\n",
    "\n",
    "- da: 37 correct out of 200 lines - 18.5%\n",
    "- de: 103 correct out of 200 lines - 51.5%\n",
    "- en: 183 correct out of 200 lines - 91.5%\n",
    "- fr: 41 correct out of 200 lines - 20.5%\n",
    "- it: 160 correct out of 200 lines - 80.0%\n",
    "- nl: 172 correct out of 200 lines - 86.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5709465-c7a1-45ac-bd51-224c96ea3659",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ddb21f-b6b3-4d6e-8876-479ef8f51c02",
   "metadata": {},
   "source": [
    "Next, I repeat the same steps with bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ba39c0-9dfe-48fd-a06f-d61230c67c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed perplexity scores for the six bigram models:\n",
      "da_bigram: 23.5642679039043\n",
      "de_bigram: 23.426090754988575\n",
      "en_bigram: 13.615689587540372\n",
      "fr_bigram: 10.366607233458831\n",
      "it_bigram: 20.40655862278738\n",
      "nl_bigram: 21.898388667057226\n",
      "{'da': 164, 'de': 192, 'en': 198, 'fr': 170, 'it': 198, 'nl': 197}\n",
      "{'da': 200, 'de': 200, 'en': 200, 'fr': 200, 'it': 200, 'nl': 200}\n",
      "82.0\n",
      "96.0\n",
      "99.0\n",
      "85.0\n",
      "99.0\n",
      "98.5\n"
     ]
    }
   ],
   "source": [
    "# Train bigram models.\n",
    "da_bigram = train_char_lm('da.train.txt', 1)\n",
    "de_bigram = train_char_lm('de.train.txt', 1)\n",
    "en_bigram = train_char_lm('en.train.txt', 1)\n",
    "fr_bigram = train_char_lm('fr.train.txt', 1)\n",
    "it_bigram = train_char_lm('it.train.txt', 1)\n",
    "nl_bigram = train_char_lm('nl.train.txt', 1)\n",
    "\n",
    "# Create predictions.\n",
    "predicted_languages = []\n",
    "actual_languages = []\n",
    "with open(\"test.txt\") as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        split_tab = line.split(\"\\t\")\n",
    "        actual_language = split_tab[0]\n",
    "        actual_languages.append(actual_language)\n",
    "        text = split_tab[1] # Only use the text after the tab. Ignore the correct language code.\n",
    "        da_score = smoothed_perplexity(text, da_bigram, 1)\n",
    "        de_score = smoothed_perplexity(text, de_bigram, 1)\n",
    "        en_score = smoothed_perplexity(text, en_bigram, 1)\n",
    "        fr_score = smoothed_perplexity(text, fr_bigram, 1)\n",
    "        it_score = smoothed_perplexity(text, it_bigram, 1)\n",
    "        nl_score = smoothed_perplexity(text, nl_bigram, 1)\n",
    "        min_score = min(da_score, de_score, en_score, fr_score, it_score, nl_score)\n",
    "        if min_score == da_score:\n",
    "            predicted_language = \"da\"\n",
    "        elif min_score == de_score:\n",
    "            predicted_language = \"de\"\n",
    "        elif min_score == en_score:\n",
    "            predicted_language = \"en\"\n",
    "        elif min_score == fr_score:\n",
    "            predicted_language = \"fr\"\n",
    "        elif min_score == it_score:\n",
    "            predicted_language = \"it\"\n",
    "        elif min_score == nl_score:\n",
    "            predicted_language = \"nl\"\n",
    "        predicted_languages.append(predicted_language)\n",
    "        # Print all the smoothed perplexity scores.\n",
    "        if i == 0:\n",
    "            print(\"Smoothed perplexity scores for the six bigram models:\")\n",
    "            print(\"da_bigram: \" + str(da_score))\n",
    "            print(\"de_bigram: \" + str(de_score))\n",
    "            print(\"en_bigram: \" + str(en_score))\n",
    "            print(\"fr_bigram: \" + str(fr_score))\n",
    "            print(\"it_bigram: \" + str(it_score))\n",
    "            print(\"nl_bigram: \" + str(nl_score))\n",
    "        i += 1\n",
    "\n",
    "# Calculate and report accuracies.\n",
    "actual_language_counts = {\n",
    "    \"da\": 0,\n",
    "    \"de\": 0,\n",
    "    \"en\": 0,\n",
    "    \"fr\": 0,\n",
    "    \"it\": 0,\n",
    "    \"nl\": 0\n",
    "}\n",
    "correct_prediction_counts = {\n",
    "    \"da\": 0,\n",
    "    \"de\": 0,\n",
    "    \"en\": 0,\n",
    "    \"fr\": 0,\n",
    "    \"it\": 0,\n",
    "    \"nl\": 0\n",
    "}\n",
    "for i in range(0, len(actual_languages)):\n",
    "    actual_language_counts[actual_languages[i]] += 1\n",
    "    if predicted_languages[i] == actual_languages[i]:\n",
    "        correct_prediction_counts[predicted_languages[i]] += 1\n",
    "print(correct_prediction_counts)\n",
    "print(actual_language_counts)\n",
    "print(correct_prediction_counts[\"da\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"de\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"en\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"fr\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"it\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"nl\"]/actual_language_counts[\"da\"]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f31614-cfc3-41a4-b805-621648eb914c",
   "metadata": {},
   "source": [
    "The bigram models produce the following results, which are displayed above:\n",
    "\n",
    "- da: 164 correct out of 200 lines - 82.0%\n",
    "- de: 192 correct out of 200 lines - 96.0%\n",
    "- en: 198 correct out of 200 lines - 99.0%\n",
    "- fr: 170 correct out of 200 lines - 85.0%\n",
    "- it: 198 correct out of 200 lines - 99.0%\n",
    "- nl: 197 correct out of 200 lines - 98.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abbc58d-386e-4bf6-abad-823b9a07c341",
   "metadata": {},
   "source": [
    "### 4-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca2a3e-a484-41be-b9f9-e54155447cbf",
   "metadata": {},
   "source": [
    "Finally, I repeat the experiment with 4-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7bdeef2-8bc6-4ed8-b4a2-96390e4fe34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed perplexity scores for the six 4-gram models:\n",
      "da_4gram: 6.72610373823322\n",
      "de_4gram: 5.998307660876636\n",
      "en_4gram: 7.246468761709272\n",
      "fr_4gram: 4.7966715688365\n",
      "it_4gram: 5.491558296054048\n",
      "nl_4gram: 7.643868612856132\n",
      "{'da': 44, 'de': 82, 'en': 103, 'fr': 105, 'it': 136, 'nl': 46}\n",
      "{'da': 200, 'de': 200, 'en': 200, 'fr': 200, 'it': 200, 'nl': 200}\n",
      "22.0\n",
      "41.0\n",
      "51.5\n",
      "52.5\n",
      "68.0\n",
      "23.0\n"
     ]
    }
   ],
   "source": [
    "# Train bigram models.\n",
    "da_4gram = train_char_lm('da.train.txt', 3)\n",
    "de_4gram = train_char_lm('de.train.txt', 3)\n",
    "en_4gram = train_char_lm('en.train.txt', 3)\n",
    "fr_4gram = train_char_lm('fr.train.txt', 3)\n",
    "it_4gram = train_char_lm('it.train.txt', 3)\n",
    "nl_4gram = train_char_lm('nl.train.txt', 3)\n",
    "\n",
    "# Create predictions.\n",
    "predicted_languages = []\n",
    "actual_languages = []\n",
    "with open(\"test.txt\") as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        split_tab = line.split(\"\\t\")\n",
    "        actual_language = split_tab[0]\n",
    "        actual_languages.append(actual_language)\n",
    "        text = split_tab[1] # Only use the text after the tab. Ignore the correct language code.\n",
    "        da_score = smoothed_perplexity(text, da_4gram, 3)\n",
    "        de_score = smoothed_perplexity(text, de_4gram, 3)\n",
    "        en_score = smoothed_perplexity(text, en_4gram, 3)\n",
    "        fr_score = smoothed_perplexity(text, fr_4gram, 3)\n",
    "        it_score = smoothed_perplexity(text, it_4gram, 3)\n",
    "        nl_score = smoothed_perplexity(text, nl_4gram, 3)\n",
    "        min_score = min(da_score, de_score, en_score, fr_score, it_score, nl_score)\n",
    "        if min_score == da_score:\n",
    "            predicted_language = \"da\"\n",
    "        elif min_score == de_score:\n",
    "            predicted_language = \"de\"\n",
    "        elif min_score == en_score:\n",
    "            predicted_language = \"en\"\n",
    "        elif min_score == fr_score:\n",
    "            predicted_language = \"fr\"\n",
    "        elif min_score == it_score:\n",
    "            predicted_language = \"it\"\n",
    "        elif min_score == nl_score:\n",
    "            predicted_language = \"nl\"\n",
    "        predicted_languages.append(predicted_language)\n",
    "        # Print all the smoothed perplexity scores.\n",
    "        if i == 0:\n",
    "            print(\"Smoothed perplexity scores for the six 4-gram models:\")\n",
    "            print(\"da_4gram: \" + str(da_score))\n",
    "            print(\"de_4gram: \" + str(de_score))\n",
    "            print(\"en_4gram: \" + str(en_score))\n",
    "            print(\"fr_4gram: \" + str(fr_score))\n",
    "            print(\"it_4gram: \" + str(it_score))\n",
    "            print(\"nl_4gram: \" + str(nl_score))\n",
    "        i += 1\n",
    "\n",
    "# Calculate and report accuracies.\n",
    "actual_language_counts = {\n",
    "    \"da\": 0,\n",
    "    \"de\": 0,\n",
    "    \"en\": 0,\n",
    "    \"fr\": 0,\n",
    "    \"it\": 0,\n",
    "    \"nl\": 0\n",
    "}\n",
    "correct_prediction_counts = {\n",
    "    \"da\": 0,\n",
    "    \"de\": 0,\n",
    "    \"en\": 0,\n",
    "    \"fr\": 0,\n",
    "    \"it\": 0,\n",
    "    \"nl\": 0\n",
    "}\n",
    "for i in range(0, len(actual_languages)):\n",
    "    actual_language_counts[actual_languages[i]] += 1\n",
    "    if predicted_languages[i] == actual_languages[i]:\n",
    "        correct_prediction_counts[predicted_languages[i]] += 1\n",
    "print(correct_prediction_counts)\n",
    "print(actual_language_counts)\n",
    "print(correct_prediction_counts[\"da\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"de\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"en\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"fr\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"it\"]/actual_language_counts[\"da\"]*100)\n",
    "print(correct_prediction_counts[\"nl\"]/actual_language_counts[\"da\"]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d51cb-36cc-4672-bf19-a4f3d422e6fd",
   "metadata": {},
   "source": [
    "The 4-gram models produce the following results, which are displayed above:\n",
    "\n",
    "- da: 44 correct out of 200 lines - 22.0%\n",
    "- de: 82 correct out of 200 lines - 41.0%\n",
    "- en: 103 correct out of 200 lines - 51.5%\n",
    "- fr: 105 correct out of 200 lines - 52.5%\n",
    "- it: 136 correct out of 200 lines - 68.0%\n",
    "- nl: 46 correct out of 200 lines - 23.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56013683-1e3b-4859-9ec8-2620ec86038a",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8077a3-f9bd-4942-bc0d-f237111fd351",
   "metadata": {},
   "source": [
    "Below is a summary of the accuracies from the three different experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eecbf5-cd2c-433f-9495-7e9f3c1838ca",
   "metadata": {},
   "source": [
    "| Language | Unigram | Bigram | 4-gram |\n",
    "| -------- | ------- | ------ | ------ |\n",
    "| da       | 18.5    | 82.0   | 22.0   |\n",
    "| de       | 51.5    | 96.0   | 41.0   |\n",
    "| en       | 91.5    | 99.0   | 51.5   |\n",
    "| fr       | 20.5    | 85.0   | 52.5   |\n",
    "| it       | 80.0    | 99.0   | 68.0   |\n",
    "| nl       | 86.0    | 98.5   | 23.0   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a80e9-0389-491b-9b02-47f3142ee487",
   "metadata": {},
   "source": [
    "The bigrams are significantly more accurate at predicting language than the unigrams across all languages. The bigrams are also better at predicting every language than the 4-grams, and the unigrams perform better on four languages than the 4-grams (de, en, it, nl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa085d-23d3-4fbb-9dc0-8cda8e201cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
